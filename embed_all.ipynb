{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "import numpy as np\n",
    "from insightface.app import FaceAnalysis\n",
    "import clip\n",
    "import torch\n",
    "from geopy.geocoders import Nominatim\n",
    "from rocksdict import Rdict\n",
    "import faiss\n",
    "import json\n",
    "from sklearn.cluster import DBSCAN\n",
    "from pillow_heif import register_heif_opener\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLOSE DATABASES IF NOT DONT ALREADY IN BELOW CELLS (WHILE RUNNING IN JUPYTER ONLY, TESTING)\n",
    "image_db.close()\n",
    "face_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESET DATABASES TO BLANK (FOR TESTING ONLY)\n",
    "import glob\n",
    "for file in glob.glob(\"new_db/*.faiss\"):\n",
    "    os.remove(file)\n",
    "for file in glob.glob(\"new_db/*.json\"):\n",
    "    os.remove(file)\n",
    "import shutil\n",
    "db_path = \"new_db/image_db\"\n",
    "if os.path.exists(db_path):\n",
    "    shutil.rmtree(db_path)\n",
    "db_path = \"new_db/face_db\"\n",
    "if os.path.exists(db_path):\n",
    "    shutil.rmtree(db_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:118: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'CoreMLExecutionProvider, AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/adityapatil/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/adityapatil/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/adityapatil/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/adityapatil/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /Users/adityapatil/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      "set det-size: (640, 640)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SET DEVICE INFO\n",
    "device = \"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# CLIP MODEL FOR SEMANTIC EMBEDDINGS\n",
    "clip_model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "\n",
    "# INSIGHTFACE MODEL (RetinaNet + MobileFaceNet)\n",
    "face_app = FaceAnalysis(name=\"buffalo_l\", detectors=['SCRFD'])\n",
    "face_app.prepare(ctx_id=0, det_size=(640, 640))\n",
    "\n",
    "# Enable HEIC support\n",
    "register_heif_opener()\n",
    "\n",
    "# Nominatim for Geolocation Address generation\n",
    "geolocator = Nominatim(user_agent=\"image_search_app\")\n",
    "\n",
    "# Elasticsearch client (NOT WORKING?)\n",
    "# es = Elasticsearch([\"http://localhost:9200\"])\n",
    "# es = Elasticsearch(\"http://localhost:9200\", node_class=RequestsHttpNode)\n",
    "# es = Elasticsearch(\"http://localhost:9200\", request_timeout=30, max_retries=10, retry_on_timeout=True)\n",
    "\n",
    "# FAISS setup for storing/searching embeddings\n",
    "clip_dim = 512\n",
    "face_dim = 512\n",
    "clip_index = faiss.IndexFlatL2(clip_dim)\n",
    "face_index = faiss.IndexFlatL2(face_dim)  # For image-specific face embeddings\n",
    "face_db_index = faiss.IndexFlatL2(face_dim)  # Face database for clustering\n",
    "\n",
    "# FACE AND METADATA STORAGE WITH RocksDict (wrapper around RocksDB)\n",
    "# face_db = {}  # {face_id: {\"embedding\": np.array, \"name\": str or None, \"count\": int}}\n",
    "# image_db.close()\n",
    "# face_db.close()\n",
    "try:\n",
    "    image_db = Rdict(\"new_db/image_db\")  # Stores image metadata\n",
    "    face_db = Rdict(\"new_db/face_db\")  # Stores face data\n",
    "except Exception as e:\n",
    "    print(\"Looks like lock is not available, closing existing db and creating new.\")\n",
    "    image_db.close()\n",
    "    face_db.close()\n",
    "    image_db = Rdict(\"new_db/image_db\")  # Stores image metadata\n",
    "    face_db = Rdict(\"new_db/face_db\")  # Stores face data\n",
    "\n",
    "# Directory containing images\n",
    "image_dir = \"ImageSamples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_metadata(image_path):\n",
    "    \"\"\"Extract date and geolocation from EXIF using Pillow.\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    exif_data = img._getexif()\n",
    "    metadata = {}\n",
    "    \n",
    "    if exif_data:\n",
    "        for tag_id, value in exif_data.items():\n",
    "            tag = TAGS.get(tag_id, tag_id)\n",
    "            if tag == \"DateTimeOriginal\":\n",
    "                metadata[\"date\"] = value\n",
    "            elif tag == \"GPSInfo\":\n",
    "                gps_data = {}\n",
    "                for t in value:\n",
    "                    sub_tag = TAGS.get(t, t)\n",
    "                    gps_data[sub_tag] = value[t]\n",
    "                lat = gps_data.get(\"GPSLatitude\")\n",
    "                lon = gps_data.get(\"GPSLongitude\")\n",
    "                if lat and lon:\n",
    "                    lat = float(lat[0]) + float(lat[1])/60 + float(lat[2])/3600\n",
    "                    lon = float(lon[0]) + float(lon[1])/60 + float(lon[2])/3600\n",
    "                    if gps_data.get(\"GPSLatitudeRef\") == \"S\":\n",
    "                        lat = -lat\n",
    "                    if gps_data.get(\"GPSLongitudeRef\") == \"W\":\n",
    "                        lon = -lon\n",
    "                    metadata[\"location\"] = (lat, lon)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def get_location_description(lat, lon):\n",
    "    \"\"\"Convert lat/lon to human-readable location using Nominatim.\"\"\"\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), language=\"en\")\n",
    "        return location.address if location else \"Unknown\"\n",
    "    except:\n",
    "        return \"Unknown\"\n",
    "\n",
    "def update_face_db(face_embedding, quality_score):\n",
    "    \"\"\"Update face database with robust embeddings.\"\"\"\n",
    "    # Search for nearest face in face_db_index\n",
    "    distances, indices = face_db_index.search(np.array([face_embedding]), k=1)\n",
    "    threshold = 0.6  # Cosine similarity threshold (tune as needed)\n",
    "    if face_db_index.ntotal == 0 or distances[0][0] > threshold:  # New face\n",
    "        face_id = str(uuid.uuid4())\n",
    "        face_db[face_id] = {\"embedding\": face_embedding, \"name\": None, \"count\": 1}\n",
    "        face_db_index.add(np.array([face_embedding]))\n",
    "    else:  # Existing face\n",
    "        face_id = list(face_db.keys())[indices[0][0]]\n",
    "        current_embedding = face_db[face_id][\"embedding\"]\n",
    "        face_db[face_id][\"count\"] += 1\n",
    "        # Update embedding if quality is high (e.g., clear image, no occlusion)\n",
    "        if quality_score > 0.9:  # Assuming quality_score from InsightFace (tune threshold)\n",
    "            face_db[face_id][\"embedding\"] = (current_embedding + face_embedding) / 2  # Average for robustness\n",
    "            face_db_index.reconstruct(indices[0][0])[:] = face_db[face_id][\"embedding\"]\n",
    "\n",
    "    return face_id\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"Process a single image: extract metadata, embeddings, and index.\"\"\"\n",
    "    image_id = str(uuid.uuid4())\n",
    "    metadata = extract_metadata(image_path)\n",
    "    date = metadata.get(\"date\", \"Unknown\")\n",
    "    loc_coords = metadata.get(\"location\")\n",
    "    location_desc = get_location_description(*loc_coords) if loc_coords else \"Unknown\"\n",
    "    \n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img_preprocessed = preprocess(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        clip_embedding = clip_model.encode_image(img_preprocessed).cpu().numpy().flatten()\n",
    "    \n",
    "    # Detect and embed faces\n",
    "    face_data = []\n",
    "    img_np = np.array(img)\n",
    "    faces = face_app.get(img_np)\n",
    "    for face in faces:\n",
    "        face_embedding = face.embedding\n",
    "        quality_score = face.det_score  # Detection confidence as proxy for quality\n",
    "        face_id = update_face_db(face_embedding, quality_score)\n",
    "        face_data.append({\"face_id\": face_id})\n",
    "    \n",
    "    # Store in Elasticsearch\n",
    "    doc = {\n",
    "        \"image_id\": image_id,\n",
    "        \"image_path\": image_path,\n",
    "        \"date\": date,\n",
    "        \"location\": location_desc,\n",
    "        \"tags\": [],\n",
    "        \"faces\": [{\"face_id\": f[\"face_id\"]} for f in face_data]\n",
    "    }\n",
    "    # es.index(index=\"images\", id=image_id, body=doc)\n",
    "    image_db[image_id.encode()] = json.dumps(doc).encode()\n",
    "    # Store CLIP embedding in FAISS\n",
    "    clip_index.add(np.array([clip_embedding]))\n",
    "    \n",
    "    # Save mapping\n",
    "    with open(\"new_db/index_mapping.json\", \"a\") as f:\n",
    "        f.write(json.dumps({\"image_id\": image_id, \"clip_idx\": clip_index.ntotal - 1}) + \"\\n\")\n",
    "    \n",
    "    return image_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/adityapatil/Glimpse/ImageSamples/UQVJ8690.JPG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/adityapatil/Glimpse/ImageSamples/IMG_6101.JPG\n",
      "Processing /Users/adityapatil/Glimpse/ImageSamples/KXMZ7727.JPG\n",
      "Processing /Users/adityapatil/Glimpse/ImageSamples/IMG_8065.JPG\n"
     ]
    }
   ],
   "source": [
    "# Process all images\n",
    "for filename in os.listdir(image_dir)[:5]:\n",
    "    if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".heic\")):\n",
    "        image_path = os.path.join(image_dir, filename)\n",
    "        print(f\"Processing {image_path}\")\n",
    "        process_image(image_path)\n",
    "\n",
    "\n",
    "# Save indices and face database\n",
    "faiss.write_index(clip_index, \"new_db/clip_index.faiss\")\n",
    "faiss.write_index(face_db_index, \"new_db/face_db_index.faiss\")\n",
    "\n",
    "import json\n",
    "\n",
    "def handle_circular_references(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()  # Convert NumPy arrays to lists\n",
    "    if isinstance(obj, dict): \n",
    "        return {k: handle_circular_references(v) for k, v in obj.items()}  # Recursively fix dicts\n",
    "    if isinstance(obj, list):\n",
    "        return [handle_circular_references(v) for v in obj]  # Recursively fix lists\n",
    "    if hasattr(obj, '__dict__'):  # Convert objects to dicts safely\n",
    "        return {k: handle_circular_references(v) for k, v in obj.__dict__.items()}\n",
    "    return str(obj)  # Convert problematic objects to strings\n",
    "\n",
    "# Now dump JSON safely\n",
    "with open(\"new_db/face_db.json\", \"w\") as f:\n",
    "    json.dump(face_db, f, default=handle_circular_references, indent=4)\n",
    "\n",
    "# Close RocksDB databases after operations\n",
    "image_db.close()\n",
    "face_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import rocksdict\n",
    "from PIL import Image\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "# Open RocksDB databases\n",
    "image_db = rocksdict.Rdict(\"new_db/image_db\")  # Stores image metadata\n",
    "face_db = rocksdict.Rdict(\"new_db/face_db\")  # Stores face data\n",
    "\n",
    "def show_top_unnamed_faces():\n",
    "    \"\"\"Show top 10 unnamed faces by frequency and display their images.\"\"\"\n",
    "    unnamed_faces = {}\n",
    "\n",
    "    for fid, data in face_db.items():\n",
    "        # Ensure data is a dict\n",
    "        if isinstance(data, bytes):  \n",
    "            data = json.loads(data.decode())  # Decode bytes to dict\n",
    "        \n",
    "        if data.get(\"name\") is None:\n",
    "            unnamed_faces[fid] = data\n",
    "    # unnamed_faces = {fid: json.loads(data) for fid, data in face_db.items() if json.loads(data)[\"name\"] is None}\n",
    "    top_faces = sorted(unnamed_faces.items(), key=lambda x: x[1][\"count\"], reverse=True)[:10]\n",
    "    \n",
    "    for face_id, data in top_faces:\n",
    "        # Search for an image containing this face ID\n",
    "        for key, img_data in image_db.items():\n",
    "            img_doc = json.loads(img_data)\n",
    "            faces = img_doc.get(\"faces\", [])\n",
    "            if any(f[\"face_id\"] == face_id for f in faces):  \n",
    "                image_path = img_doc.get(\"image_path\")\n",
    "                if not image_path:\n",
    "                    print(f\"Face ID: {face_id}, Count: {data['count']}, No image path found!\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    img = Image.open(image_path).convert(\"RGB\")  # Open image from stored path\n",
    "                    \n",
    "                    # If bounding box data exists, crop face\n",
    "                    face_bbox = next((f[\"bbox\"] for f in faces if f[\"face_id\"] == face_id), None)\n",
    "                    if face_bbox:\n",
    "                        x, y, w, h = face_bbox\n",
    "                        face_img = img.crop((x, y, x + w, y + h))\n",
    "                    else:\n",
    "                        face_img = img  # Show full image if no bounding box\n",
    "                    \n",
    "                    # Display face inline\n",
    "                    plt.figure(figsize=(2, 2))\n",
    "                    plt.imshow(face_img)\n",
    "                    plt.axis(\"off\")\n",
    "                    plt.show()\n",
    "\n",
    "                    print(f\"Face ID: {face_id}, Count: {data['count']}, Image: {image_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image {image_path}: {e}\")\n",
    "                \n",
    "                break  # Stop after finding the first relevant image\n",
    "\n",
    "def rename_faces(face_id_name_pairs):\n",
    "    \"\"\"Rename specified face IDs.\"\"\"\n",
    "    for face_id, name in face_id_name_pairs.items():\n",
    "        face_id_encoded = face_id.encode()\n",
    "        \n",
    "        if face_id_encoded in face_db:\n",
    "            face_data = face_db[face_id_encoded]\n",
    "            \n",
    "            if isinstance(face_data, bytes):  \n",
    "                face_data = json.loads(face_data.decode())  # Decode bytes to dict\n",
    "            \n",
    "            face_data[\"name\"] = name\n",
    "            face_db[face_id_encoded] = json.dumps(face_data).encode()  # Store back in RocksDB\n",
    "            print(f\"Renamed {face_id} to {name}\")\n",
    "\n",
    "# Close RocksDB databases after operations\n",
    "image_db.close()\n",
    "face_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading image /Users/adityapatil/Glimpse/ImageSamples/IMG_8065.JPG: 'bbox'\n",
      "Face ID: 082686fe-4436-4c81-a430-c156905a5018, Count: 1, No image path found!\n",
      "Face ID: 166bb535-1ff6-44c8-8d61-1a0dc07a0d7e, Count: 1, No image path found!\n",
      "Face ID: 3097c8de-457b-48af-9f73-809a0ee96428, Count: 1, No image path found!\n",
      "Error loading image /Users/adityapatil/Glimpse/ImageSamples/KXMZ7727.JPG: 'bbox'\n",
      "Face ID: 3a1408e4-ee14-4c0f-8f9e-5bc6b78a1535, Count: 1, No image path found!\n",
      "Error loading image /Users/adityapatil/Glimpse/ImageSamples/IMG_6101.JPG: 'bbox'\n",
      "Face ID: 50bdc786-996a-4eb6-8558-4bd43a963756, Count: 1, No image path found!\n",
      "Error loading image /Users/adityapatil/Glimpse/ImageSamples/KXMZ7727.JPG: 'bbox'\n",
      "Face ID: 606f776b-f4b6-4559-8753-1ba9b1c78224, Count: 1, No image path found!\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "# Open RocksDB databases\n",
    "image_db = rocksdict.Rdict(\"new_db/image_db\")  # Stores image metadata\n",
    "face_db = rocksdict.Rdict(\"new_db/face_db\")  # Stores face data\n",
    "show_top_unnamed_faces()\n",
    "image_db.close()\n",
    "face_db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rename_faces({\"face_id_1\": \"Emma\", \"face_id_2\": \"John\"})  # Replace with actual IDs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvGlimpse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
